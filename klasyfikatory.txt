No StandardScaler:

Random Forest
Accuracy: 68.5925925925926%
AUC ROC: 68.51134314750833%
Decision Tree
Accuracy: 57.57037037037037%
AUC ROC: 57.58353275180635%
Naive Bayes
Accuracy: 57.15555555555556%
AUC ROC: 57.316363506103365%
3NN
Accuracy: 59.46666666666667%
AUC ROC: 59.542604144205015%
5NN
Accuracy: 58.25185185185185%
AUC ROC: 58.32693578736875%
11NN
Accuracy: 56.68148148148148%
AUC ROC: 56.74448259949442%
Neural Network
Accuracy: 49.570369720458984%
AUC ROC: 50.0%

With StandardScaler:
Random Forest
Accuracy: 68.53333333333333%
AUC ROC: 68.45106105611836%
Decision Tree
Accuracy: 57.68888888888889%
AUC ROC: 57.70206002150699%
Naive Bayes
Accuracy: 64.02962962962962%
AUC ROC: 64.00965988468262%
3NN
Accuracy: 63.25925925925926%
AUC ROC: 63.365012014275244%
5NN
Accuracy: 63.05185185185185%
AUC ROC: 63.15835313470387%
11NN
Accuracy: 60.53333333333333%
AUC ROC: 60.64346786558902%
Neural Network
Accuracy: 63.822221755981445%
AUC ROC: 67.494589888623%
Neural Network (overfitting)
Accuracy: 60.44444441795349%
AUC ROC: 66.87279592465987%

Dropout - pomaga zapobiegać przetrenowaniu przez losowe wyłączanie pewnej liczby neuronów podczas każdej epoki treningowej, co pomaga zapobiegać zbyt dużemu dopasowaniu do danych treningowych.
kernel_regularizer - dodaje karę do funkcji straty na podstawie wielkości wag, co pomaga zapobiegać przetrenowaniu przez zmuszanie wag do przyjmowania mniejszych wartości.
EarlyStopping - zatrzymuje proces uczenia, gdy model przestaje się poprawiać na zbiorze walidacyjnym, co pomaga zapobiegać przetrenowaniu przez zakończenie uczenia, zanim model zacznie zbyt mocno dopasowywać się do danych treningowych.